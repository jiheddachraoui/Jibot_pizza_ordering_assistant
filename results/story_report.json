{
  "utter_item_change": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 1
  },
  "utter_order_complete": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 7
  },
  "pizza_order_form": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 9
  },
  "utter_welcome_greet": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 7
  },
  "action_end_conversation": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 3
  },
  "give_rating": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "init_pizza_question": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "action_save_feedback": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 3
  },
  "action_listen": {
    "precision": 0.9629629629629629,
    "recall": 1.0,
    "f1-score": 0.9811320754716981,
    "support": 52
  },
  "utter_init_pizza_question": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "response_negative": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 4
  },
  "item_start_generic": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8
  },
  "person_form": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 7
  },
  "accept_feedback": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 5
  },
  "action_reset_pizza_form": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "item_type_start_negative": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "welcome_greet": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 7
  },
  "utter_init_request": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "order_delivery": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 3
  },
  "goodbye": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 7
  },
  "init_request": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "order_take_home": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 4
  },
  "utter_order_add": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "item_change": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "feedback_form": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 5
  },
  "utter_feedback": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 7
  },
  "utter_thank_user": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6
  },
  "utter_total_order_final": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 7
  },
  "utter_order_confirm_negative": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "action_order_number": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 7
  },
  "utter_summarize_order": {
    "precision": 1.0,
    "recall": 0.8888888888888888,
    "f1-score": 0.9411764705882353,
    "support": 9
  },
  "action_change_order": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "response_positive": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 7
  },
  "utter_item_type_start_negative": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "accuracy": 0.9842931937172775,
  "macro avg": {
    "precision": 0.9253812636165577,
    "recall": 0.9379084967320261,
    "f1-score": 0.9290875062566648,
    "support": 191
  },
  "weighted avg": {
    "precision": 0.9768276129532674,
    "recall": 0.9842931937172775,
    "f1-score": 0.9798749886203617,
    "support": 191
  },
  "micro avg": {
    "precision": 0.9842931937172775,
    "recall": 0.9842931937172775,
    "f1-score": 0.9842931937172775,
    "support": 191
  },
  "conversation_accuracy": {
    "accuracy": 0.8571428571428571,
    "correct": 6,
    "with_warnings": 0,
    "total": 7
  }
}